{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "import fileinput\n",
    "import pickle\n",
    "import os\n",
    "# import skimage.io\n",
    "# import skimage.transform\n",
    "# from keras.preprocessing.text import Tokenizer, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dchenam/miniconda3/envs/pytorch/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (43,44,45,46,47,48,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33431\n"
     ]
    }
   ],
   "source": [
    "tags = pd.read_csv('~/Dataset/anime/tags_clean.csv', header=None, sep='\\t', names=list(range(50)))\n",
    "print(len(tags))\n",
    "clean = tags.applymap(lambda x:re.sub('[\\d,:\"\"]','', str(x)))\n",
    "mask = clean.applymap(lambda x:(\"eyes\" in str(x)) or (\"hair\" in str(x)))\n",
    "clean = clean.where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.to_csv('tags_clean.txt', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fileinput.input('tags_clean.txt', inplace=1)\n",
    "for line in x:\n",
    "    line = re.sub('\\t', ' ', line)\n",
    "    line = re.sub(\"long hair\", ' ', line)\n",
    "    line = re.sub(\"short hair\", ' ', line)\n",
    "    if not ('hair' in line) and not ('eye' in line):\n",
    "        line = ''\n",
    "    if line.count('hair') > 1:\n",
    "        line = ''\n",
    "    if line.count('eyes') > 1:\n",
    "        line = ''\n",
    "    line = re.sub(\"pubic hair\", ' ', line)\n",
    "    line = re.sub(\"rutherford\", ' ', line)\n",
    "    line = re.sub(\"  eyes  \", ' ', line)\n",
    "    line = re.sub(\"  hair  \", ' ', line)\n",
    "    line = re.sub(' hair', '_hair', line)\n",
    "    line = re.sub(' eye', '_eye', line)\n",
    "    line = re.sub('\\s{2,}', ' ', line.strip())\n",
    "    if re.match(r'^\\s*$', line):\n",
    "        continue\n",
    "    print(line.strip())\n",
    "x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('tags_clean.txt', 'r') as f:\n",
    "    data.extend(line for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "captions = []\n",
    "for line in data:\n",
    "    idx.append(int(re.findall(r'\\d+', line)[0]))\n",
    "    captions.append(re.sub(\"\\d+\\s\", \"\", line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "img_data = []\n",
    "for i in idx:\n",
    "    img = skimage.io.imread(os.path.join('data/faces', str(i) + '.jpg'))\n",
    "    img = skimage.transform.resize(img, (64, 64))\n",
    "    img_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = np.array(img_data)\n",
    "img_data = img_data * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_images.npy', img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from skip_thoughts import configuration\n",
    "from skip_thoughts import encoder_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_FILE = \"skip_thoughts_uni/vocab.txt\"\n",
    "EMBEDDING_MATRIX_FILE = \"skip_thoughts_uni/embeddings.npy\"\n",
    "CHECKPOINT_PATH = \"skip_thoughts_uni/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading vocabulary from skip_thoughts_uni/vocab.txt\n",
      "INFO:tensorflow:Loaded vocabulary with 930914 words.\n",
      "INFO:tensorflow:Loading embedding matrix from skip_thoughts_uni/embeddings.npy\n",
      "INFO:tensorflow:Loaded embedding matrix with shape (930914, 620)\n",
      "INFO:tensorflow:Building model.\n",
      "INFO:tensorflow:Loading model from checkpoint: skip_thoughts_uni/model.ckpt-501424\n",
      "INFO:tensorflow:Restoring parameters from skip_thoughts_uni/model.ckpt-501424\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-501424\n"
     ]
    }
   ],
   "source": [
    "encoder = encoder_manager.EncoderManager()\n",
    "encoder.load_model(configuration.model_config(),\n",
    "                   vocabulary_file=VOCAB_FILE,\n",
    "                   embedding_matrix_file=EMBEDDING_MATRIX_FILE,\n",
    "                   checkpoint_path=CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = encoder.encode(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = np.array(encodings)\n",
    "np.save('train_embeddings.npy', encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as sd\n",
    "def get_nn(ind, num=10):\n",
    "  encoding = encodings[ind]\n",
    "  scores = sd.cdist([encoding], encodings, \"cosine\")[0]\n",
    "  sorted_ids = np.argsort(scores)\n",
    "  print(\"Sentence:\")\n",
    "  print(\"\", caption[ind])\n",
    "  print(\"\\nNearest neighbors:\")\n",
    "  for i in range(1, num + 1):\n",
    "    print(\" %d. %s (%.3f)\" %\n",
    "          (i, caption[sorted_ids[i]], scores[sorted_ids[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'orange hair':'1', 'white hair':'2', 'aqua hair':'3', 'gray hair':'4',\n",
    "    'green hair':'5', 'red hair':'6', 'purple hair':'7', 'pink hair':'8',\n",
    "    'blue hair':'9', 'black hair':'10', 'brown hair':'11', 'blonde hair':'12','gray eyes': '13',\n",
    "    'black eyes':'14', 'orange eyes':'15', 'blue eyes': '24',\n",
    "    'pink eyes':'16', 'yellow eyes':'17', 'aqua eyes':'18', 'purple eyes':'19',\n",
    "    'green eyes':'20', 'brown eyes':'21', 'red eyes':'22', 'bicolored eyes':'23'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "for hair in color_hairs:\n",
    "    for eye in color_eyes:\n",
    "        testing_data.append(hair + ' ' + eye)\n",
    "        testing_data.append(eye + ' ' + hair)\n",
    "for hair in color_hairs:\n",
    "    testing_data.append(hair)\n",
    "for eye in color_eyes:\n",
    "    testing_data.append(eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('|'.join(d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599 eyes\n",
      "3695 pubic hair 19\n",
      "4555 eyes\n",
      "6156 eyes 6\n",
      "7016 eyes\n",
      "7403 eyes rutherford\n",
      "10002 eyes rutherford\n",
      "11437 eyes\n",
      "13655 eyes\n",
      "14214 eyes\n"
     ]
    }
   ],
   "source": [
    "for i, caption in enumerate(captions):\n",
    "    result = pattern.sub(lambda x: d[x.group()], caption)\n",
    "    try:\n",
    "        caption = [int(s) for s in result.split(' ')]\n",
    "    except:\n",
    "        print(i, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_captions = tokenizer.texts_to_matrix(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_captions.npy', tokenized_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_encoding = encoder.encode(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_encoding = tokenizer.texts_to_matrix(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dict = dict(zip(testing_data, testing_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.04750069e-02,  -6.59986362e-02,  -4.85626333e-05, ...,\n",
       "         5.74678509e-03,  -6.31452072e-04,  -2.37361155e-02], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dict['aqua eyes blonde hair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as sd\n",
    "def get_nn(ind, num=10):\n",
    "  encoding = testing_encoding[ind]\n",
    "  scores = sd.cdist([encoding], encodings, \"cosine\")[0]\n",
    "  sorted_ids = np.argsort(scores)\n",
    "  print(\"Sentence:\")\n",
    "  print(\"\", testing_data[ind])\n",
    "  print(\"\\nNearest neighbors:\")\n",
    "  for i in range(1, num + 1):\n",
    "    print(\" %d. %s (%.3f)\" %\n",
    "          (i, filtered_data[sorted_ids[i]], scores[sorted_ids[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      " brown eyes orange hair\n",
      "\n",
      "Nearest neighbors:\n",
      " 1. brown eyes orange hair (0.000)\n",
      " 2. brown eyes orange hair (0.000)\n",
      " 3. brown eyes orange hair (0.000)\n",
      " 4. brown eyes orange hair (0.000)\n",
      " 5. brown eyes orange hair (0.000)\n",
      " 6. brown eyes orange hair (0.000)\n",
      " 7. green eyes orange hair (0.036)\n",
      " 8. green eyes orange hair (0.036)\n",
      " 9. green eyes orange hair (0.036)\n",
      " 10. green eyes orange hair (0.036)\n"
     ]
    }
   ],
   "source": [
    "get_nn(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = pickle.dump(testing_dict, open('test_embeddings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(12288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "a *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from int64 to float64\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/io/_io.py:132: UserWarning: test.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:118: UserWarning: Possible sign loss when converting negative image of type int64 to positive image of type uint8.\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/util/dtype.py:171: UserWarning: Downcasting int64 to uint8 without scaling because max value 254 fits in uint8\n",
      "  \"value {} fits in {}\".format(a.dtype, dtype, a.max(), dtype))\n"
     ]
    }
   ],
   "source": [
    "import skimage.io\n",
    "skimage.io.imsave('test.jpg', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = pickle.load(open('test_embeddings.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.load('train_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(len(test_embeddings), size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0155213 , -0.06247005,  0.00972278, ..., -0.00265473,\n",
       "        -0.00262971, -0.0101154 ],\n",
       "       [ 0.00730582, -0.06180365,  0.02337626, ..., -0.00276405,\n",
       "        -0.00388468, -0.00573695],\n",
       "       [ 0.00535974, -0.06033414,  0.02247241, ...,  0.00122462,\n",
       "        -0.00298307,  0.00044312],\n",
       "       ..., \n",
       "       [ 0.00701852, -0.06228148,  0.022693  , ..., -0.00914285,\n",
       "         0.00590803, -0.00861985],\n",
       "       [-0.01162465, -0.05671365,  0.02520377, ...,  0.00193969,\n",
       "         0.00093961, -0.01516995],\n",
       "       [ 0.00578264, -0.05740115,  0.01656133, ..., -0.00552971,\n",
       "        -0.00404952, -0.01117698]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(test_embeddings.values()))[random_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
